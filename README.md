# TransformerのAttentionの離散化
- ディレクトリ構造:
discretized_transformer_with_GS
    ├── models
    │   ├── discritized_transformer.py
    │   └── transformer.py
    ├── train.py
    ├── evaluate.py
    └── utils.py

# タスク
w#w'の逆順コピー
学習長は初期は3で, 最大20までのスケジューリングを行う.
